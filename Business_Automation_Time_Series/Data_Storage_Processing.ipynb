{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# AWS Configuration\n",
    "aws_access_key = 'YOUR_AWS_ACCESS_KEY'\n",
    "aws_secret_key = 'YOUR_AWS_SECRET_KEY'\n",
    "region_name = 'us-east-1'\n",
    "redshift_endpoint = 'redshift-cluster.endpoint.amazonaws.com'\n",
    "redshift_user = 'username'\n",
    "redshift_password = 'password'\n",
    "redshift_db = 'dev'\n",
    "\n",
    "# Initialize AWS Glue client\n",
    "glue_client = boto3.client('glue',\n",
    "                           aws_access_key_id=aws_access_key,\n",
    "                           aws_secret_access_key=aws_secret_key,\n",
    "                           region_name=region_name)\n",
    "\n",
    "# Function to trigger Glue ETL job\n",
    "def trigger_glue_job(job_name, args={}):\n",
    "    response = glue_client.start_job_run(JobName=job_name, Arguments=args)\n",
    "    return response['JobRunId']\n",
    "\n",
    "# Function to load data into Redshift\n",
    "def load_data_to_redshift(df, table_name):\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=redshift_db,\n",
    "        user=redshift_user,\n",
    "        password=redshift_password,\n",
    "        host=redshift_endpoint,\n",
    "        port='5439'\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create table if not exists\n",
    "    create_table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        ds DATE,\n",
    "        y FLOAT\n",
    "    );\n",
    "    \"\"\"\n",
    "    cursor.execute(create_table_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    # Insert data\n",
    "    for index, row in df.iterrows():\n",
    "        insert_query = f\"INSERT INTO {table_name} (ds, y) VALUES ('{row['ds']}', {row['y']});\"\n",
    "        cursor.execute(insert_query)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    print(\"Data loaded into Redshift.\")\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Trigger AWS Glue ETL job to process raw data\n",
    "    glue_job_name = 'business_sales_etl'\n",
    "    job_run_id = trigger_glue_job(glue_job_name)\n",
    "    print(f\"Triggered Glue job with Run ID: {job_run_id}\")\n",
    "    \n",
    "    # Load processed data into Redshift\n",
    "    processed_data = pd.read_csv('processed_business_sales.csv')  # Assume Glue job outputs this\n",
    "    load_data_to_redshift(processed_data, 'business_sales')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
